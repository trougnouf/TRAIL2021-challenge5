{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solar-hughes",
   "metadata": {},
   "source": [
    "# Self-Supervised Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "furnished-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Resize, Compose, CenterCrop, Normalize\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-douglas",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "headed-mercy",
   "metadata": {},
   "source": [
    "\n",
    "from pl_bolts.models.self_supervised.simclr import SimCLREvalDataTransform, SimCLRTrainDataTransform\n",
    "\n",
    "image_size=(224, 224)\n",
    "rop_dim=224\n",
    "train_set = ImageFolder(\n",
    "    #root=\"/home/these/DataFast/Dataset/chest_x_ray/single_label/train/\",\n",
    "    root=\"/home/these/DataFast/Dataset/chestXpert/train/\",\n",
    "    transform= SimCLRTrainDataTransform(input_height=256)\n",
    "  \n",
    "        #Compose([\n",
    "        #Resize(image_size),\n",
    "        #CenterCrop(crop_dim),\n",
    "        #ToTensor(),\n",
    "        #Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        \n",
    "   # ])\n",
    ")\n",
    "test_set = ImageFolder(\n",
    "    #root=\"~/DataFast/Dataset/chest_x_ray/single_label/test\",\n",
    "    root=\"/home/these/DataFast/Dataset/chestXpert/train/\",\n",
    "    #root=\"/home/these/DataFast/Dataset/chestXpert/CheXpert-v1.0-small/valid/\",\n",
    "    transform=Compose([\n",
    "        Resize(image_size),\n",
    "        #CenterCrop(crop_dim),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_ = DataLoader(train_set, batch_size=32, shuffle=False, num_workers=3, drop_last=True)\n",
    "test = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-jerusalem",
   "metadata": {},
   "source": [
    "## 1. SwAV (re)training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-bridge",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "biological-testing",
   "metadata": {},
   "source": [
    "from pl_bolts.models.self_supervised import SwAV\n",
    "\n",
    "weight_path = 'https://pl-bolts-weights.s3.us-east-2.amazonaws.com/swav/swav_imagenet/swav_imagenet.pth.tar'\n",
    "#model = SwAV.load_from_checkpoint(weight_path, strict=True).models"
   ]
  },
  {
   "cell_type": "raw",
   "id": "consolidated-thirty",
   "metadata": {},
   "source": [
    "model = SwAV(\n",
    "    gpus=1,\n",
    "    num_samples=len(train_set),\n",
    "    dataset='x',\n",
    "    batch_size=32,\n",
    "    queue_path='runs',\n",
    ")\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "defensive-prospect",
   "metadata": {},
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "mc = ModelCheckpoint()\n",
    "cb = [mc]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "greek-president",
   "metadata": {},
   "source": [
    "# fit\n",
    "trainer = pl.Trainer(precision=16, gpus=1, log_every_n_steps=10, progress_bar_refresh_rate=1, callbacks=cb)\n",
    "trainer.fit(model, train_dataloader=train_, val_dataloaders=test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "innovative-assault",
   "metadata": {},
   "source": [
    "lab = []\n",
    "for i, data in enumerate(train_):\n",
    "    a, b = data\n",
    "    lab.append(b.numpy())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ranging-acrobat",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "miniature-tuner",
   "metadata": {},
   "source": [
    "import pandas as pd \n",
    "a = pd.read_csv('/home/these/DataFast/Dataset/chestXpert/CheXpert-v1.0-small/train.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "amended-prison",
   "metadata": {},
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "gross-newfoundland",
   "metadata": {},
   "source": [
    "label = a[a.columns[np.asarray([5, 7, 10, 12, 13, 14])]].values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "disciplinary-macintosh",
   "metadata": {},
   "source": [
    "from tqdm import tqdm\n",
    "label[np.isnan(label)] = 0\n",
    "label = np.abs(label)\n",
    "\n",
    "t = []\n",
    "for l in tqdm(label):\n",
    "    t.append(str(l))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "measured-dominican",
   "metadata": {},
   "source": [
    "np.unique(t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.self_supervised import SwAV\n",
    "from pl_bolts.models.self_supervised.swav import SwAVEvalDataTransform, SimCLRTrainDataTransform\n",
    "import pytorch_lightning as pl\n",
    "#import FFHQDataModule as dm\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "from torchvision import datasets, transforms\n",
    "import cv2\n",
    "\n",
    "\n",
    "data_dir = '/home/these/DataFast/Dataset/chestXpert/train/'\n",
    "train_proportion = 0.8\n",
    "batch_size = 32\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir, transform=SimCLRTrainDataTransform(input_height=128))\n",
    "\n",
    "num_samples = len(os.listdir(data_dir+ '/data'))\n",
    "\n",
    "train_size = int(train_proportion*num_samples)\n",
    "val_size = int(((1-train_proportion)/2)*num_samples)\n",
    "test_size = int(((1-train_proportion)/2)*num_samples)\n",
    "\n",
    "\n",
    "train, val, test = torch.utils.data.random_split(dataset, [train_size, val_size, num_samples-train_size-val_size])\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = SimCLR(num_samples=train_size, batch_size=batch_size, dataset='chexper', gpus=1)\n",
    "\n",
    "# fit\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model, train_dl, val_dl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-basics",
   "metadata": {},
   "source": [
    "## 2. SimCLR (re)training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "pressed-scanner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/these/anaconda3/envs/vic/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1294: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | encoder    | ResNet     | 25.6 M\n",
      "1 | projection | Projection | 4.5 M \n",
      "------------------------------------------\n",
      "30.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "30.0 M    Total params\n",
      "120.078   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/these/anaconda3/envs/vic/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:372: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/these/anaconda3/envs/vic/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/these/anaconda3/envs/vic/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/these/anaconda3/envs/vic/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:322: UserWarning: The number of training samples (30) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc7ab1c01c44a099ce479293de7c159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | -1/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/these/anaconda3/envs/vic/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1046: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "from pl_bolts.models.self_supervised.simclr import SimCLREvalDataTransform, SimCLRTrainDataTransform\n",
    "import pytorch_lightning as pl\n",
    "#import FFHQDataModule as dm\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "from torchvision import datasets, transforms\n",
    "import cv2\n",
    "\n",
    "\n",
    "data_dir = '/home/these/DataFast/Dataset/chestXpert/train/'\n",
    "train_proportion = 0.8\n",
    "batch_size = 32\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir, transform=SimCLRTrainDataTransform(input_height=128))\n",
    "\n",
    "num_samples = len(os.listdir(data_dir+ '/data'))\n",
    "\n",
    "train_size = int(train_proportion*num_samples)\n",
    "val_size = int(((1-train_proportion)/2)*num_samples)\n",
    "test_size = int(((1-train_proportion)/2)*num_samples)\n",
    "\n",
    "\n",
    "train, val, test = torch.utils.data.random_split(dataset, [train_size, val_size, num_samples-train_size-val_size])\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = SimCLR(num_samples=train_size, batch_size=batch_size, dataset='chexper', gpus=1)\n",
    "\n",
    "# fit\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model, train_dl, val_dl)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
